{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "mount_file_id": "1ApY1rdr7_Ej4siofhnFuMDSKcEBdGSt7",
      "authorship_tag": "ABX9TyNGJmASSaLrJbh9JSCgz6zg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dusruddl2/dusruddl2/blob/main/lab04%2605%20%2B%20%EA%B3%BC%EC%A0%9C3%EC%A0%95%EB%A6%AC\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_92fAdwUP7-",
        "outputId": "648f58cc-5a9d-4e04-8994-b716e2c0cdc1"
      },
      "source": [
        "try:\n",
        "  # This %tensorflow_version magic only works in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# For your non-Colab code, be sure you have tensorflow==1.15\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('1')\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_1Ty5nsUaeP"
      },
      "source": [
        "#4-1\n",
        "x1_data = [73.,93.,89.,96.,73.]\n",
        "x2_data = [80.,88.,91.,98.,66.]\n",
        "x3_data = [75.,93.,90.,100.,70.]\n",
        "y_data = [152.,185.,180.,196.,142.]\n",
        "\n",
        "#placeholders for a tensor that will be always fed.\n",
        "x1 = tf.placeholder(tf.float32)\n",
        "x2 = tf.placeholder(tf.float32)\n",
        "x3 = tf.placeholder(tf.float32)\n",
        "\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([1]),name=\"weight1\")\n",
        "w2 = tf.Variable(tf.random_normal([1]),name=\"weight2\")\n",
        "w3 = tf.Variable(tf.random_normal([1]),name=\"weight3\")\n",
        "b = tf.Variable(tf.random_normal([1]),name=\"bias\")\n",
        "\n",
        "hypothesis = x1*w1+x2*w2+x3*w3+b\n",
        "\n",
        "# cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
        "# Minimize. Need a very small learning rate for this data set\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "#Launch the graph in a session\n",
        "sess = tf.Session()\n",
        "#Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  cost_val,hy_val,_=sess.run([cost,hypothesis,train],\n",
        "                             feed_dict={x1:x1_data,x2:x2_data,x3:x3_data,Y:y_data})\n",
        "  if step%10 ==0:\n",
        "    print(step,\"Cost: \",cost_val,\"\\nPrediction:\\n\",hy_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8eA73rXbMWu"
      },
      "source": [
        " #4-1\n",
        " x_data = [[73.,80.,75],[93.,88.,93],[89.,91.,90.],[96.,98.,100.],[73.,66.,70.]]\n",
        " y_data = [[152.],[185.],[180.],[196.],[142.]]\n",
        "\n",
        " # placeholders for a tensor that will be always fed\n",
        " X = tf.placeholder(tf.float32,shape=[None,3])\n",
        " Y = tf.placeholder(tf.float32,shape=[None,1])\n",
        "\n",
        " W = tf.Variable(tf.random_normal([3,1]),name=\"weight\")\n",
        " b = tf.Variable(tf.random_normal([1]),name = \"bias\")\n",
        "\n",
        " # Hypothesis\n",
        " hypothesis = tf.matmul(X,W)+b\n",
        " \n",
        " # Simplified cost/loss function\n",
        " cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
        "\n",
        " # Minimize\n",
        " optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        " train = optimizer.minimize(cost)\n",
        "\n",
        " # Launch the graph in a session\n",
        " sess = tf.Session()\n",
        " # Initializes global variables in the graph\n",
        " sess.run(tf.global_variables_initializer())\n",
        "\n",
        " for step in range(2001):\n",
        "   cost_val,hy_val,_ = sess.run(\n",
        "       [cost,hypothesis,train],feed_dict={X:x_data,Y:y_data})\n",
        "   if step%10 == 0:\n",
        "     print(step,\"Cost: \",cost_val,\"\\nPrediction:\\n\",hy_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvMWwVYQeMBA"
      },
      "source": [
        "#4-2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "xy = np.loadtxt('test_score.csv',delimiter=',',dtype=np.float32,skiprows=1)\n",
        "x_data = xy[:,0:-1]\n",
        "y_data = xy[:,[-1]]\n",
        "\n",
        "# Make sure the shape and data are OK\n",
        "print(x_data.shape,x_data,len(x_data))\n",
        "print(y_data.shape,y_data)\n",
        "\n",
        "# placeholders for a tensor that will be always fed.\n",
        "X = tf.placeholder(tf.float32,shape=[None,3])\n",
        "Y = tf.placeholder(tf.float32,shape=[None,1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3,1]),name=\"weight\")\n",
        "b = tf.Variable(tf.random_normal([1]),name=\"bias\")\n",
        "\n",
        "# Hypothesis\n",
        "hypothesis = tf.matmul(X,W)+b\n",
        "\n",
        "# Simplified cost/Loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
        "\n",
        "# Minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Set up feed_dict variables inside the loop\n",
        "for step in range(2001):\n",
        "  cost_val,hy_val,_=sess.run([cost,hypothesis,train],\n",
        "                             feed_dict={X:x_data,Y:y_data})\n",
        "  if step%10 == 0:\n",
        "    print(step,\"Cost: \",cost_val,\"\\nPrediction:\\n\",hy_val)\n",
        "\n",
        "# Ask my score\n",
        "# 내 성적\n",
        "print(\"Your score will be \",sess.run(hypothesis,feed_dict={X:[[100,70,101]]}))\n",
        "# 친구 1 & 친구 2\n",
        "print(\"Your score will be \",sess.run(hypothesis,feed_dict={X:[[60,70,110],[90,100,80]]}))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNsfTUo9Yas3"
      },
      "source": [
        "#5\n",
        "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
        "y_data = [[0],[0],[0],[1],[1],[1]]\n",
        "\n",
        "# placeholders for a tensor that will be always fed.\n",
        "X = tf.placeholder(tf.float32,shape=[None,2])\n",
        "Y = tf.placeholder(tf.float32,shape=[None,1])\n",
        "W = tf.Variable(tf.random_normal([2,1]),name=\"weight\")\n",
        "b = tf.Variable(tf.random_normal([1]),name=\"bias\")\n",
        "\n",
        "# Hypothesis using sigmoid: tf.div(1.,1.+tf.exp(tf.matmul(X,W)+b))\n",
        "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
        "\n",
        "# cost/loss function\n",
        "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "# Accuracy computation\n",
        "# True if hypothesis > 0.5 else False\n",
        "predicted = tf.cast(hypothesis>0.5,dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y),dtype=tf.float32))\n",
        "\n",
        "# Launch graph\n",
        "with tf.Session() as sess:\n",
        "  # Intialize TensorFlow variables\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for step in range(10001):\n",
        "    cost_val,_ = sess.run([cost,train],feed_dict={X:x_data,Y:y_data})\n",
        "    if step%200 == 0:\n",
        "      print(step,cost_val)\n",
        "  \n",
        "  # Accuracy report\n",
        "  h,c,a = sess.run([hypothesis,predicted,accuracy],\n",
        "                 feed_dict = {X:x_data,Y:y_data})\n",
        "  \n",
        "  print(\"\\nHypothesis: \",h,\"\\nCorrect(Y): \",c,\"\\nAccuracy:\",a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8HqVeVhfQKL"
      },
      "source": [
        " xy = np.loadtxt('data-03-diabetes.csv',delimiter=',',dtype=np,float32)\n",
        " x_data = xy[:,0:-1]\n",
        " y_data = xy[:[-1]]\n",
        "\n",
        " \n",
        " # placeholders for a tensor that will be always fed.\n",
        "X = tf.placeholder(tf.float32,shape=[None,2])\n",
        "Y = tf.placeholder(tf.float32,shape=[None,1])\n",
        "W = tf.Variable(tf.random_normal([2,1]),name=\"weight\")\n",
        "b = tf.Variable(tf.random_normal([1]),name=\"bias\")\n",
        "\n",
        "# Hypothesis using sigmoid: tf.div(1.,1.+tf.exp(tf.matmul(X,W)+b))\n",
        "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
        "\n",
        "# cost/loss function\n",
        "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "# Accuracy computation\n",
        "# True if hypothesis > 0.5 else False\n",
        "predicted = tf.cast(hypothesis>0.5,dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y),dtype=tf.float32))\n",
        "\n",
        "# Launch graph\n",
        "with tf.Session() as sess:\n",
        "  # Intialize TensorFlow variables\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for step in range(10001):\n",
        "    cost_val,_ = sess.run([cost,train],feed_dict={X:x_data,Y:y_data})\n",
        "    if step%200 == 0:\n",
        "      print(step,cost_val)\n",
        "  \n",
        "  # Accuracy report\n",
        "  h,c,a = sess.run([hypothesis,predicted,accuracy],\n",
        "                 feed_dict = {X:x_data,Y:y_data})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GH0Gv1GgUn2"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1wjjSyWXV1S"
      },
      "source": [
        "# 문제 1\n",
        "(c) local minima가 많아 global minima를 찾기 어려워짐\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "2LmTHCnrwe9l",
        "outputId": "c3f5baaa-3fa4-4f04-ab04-78c6abd3547a"
      },
      "source": [
        "# 문제 2\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset.csv')\n",
        "df\n",
        "\n",
        "#sol1) df.iloc: 행 번호를 기준으로 행 데이터 읽기\n",
        "x_data = df.iloc[0:3]    # 2가지 방법으로 작성하세요\n",
        "y_data = df.iloc[-1]    # 2가지 방법으로 작성하세요\n",
        "\n",
        "print(x_data.shape,x_data)     \n",
        "print(y_data.shape,y_data)     \n",
        "\n",
        "#sol2) df.loc: 인덱스 기준으로 행 데이터 읽기\n",
        "x_data = df.loc[0:3]    # 2가지 방법으로 작성하세요\n",
        "y_data = df.loc[4]    # 2가지 방법으로 작성하세요\n",
        " \n",
        "print(x_data.shape,x_data)     \n",
        "print(y_data.shape,y_data)     \n",
        "\n",
        "\n",
        "# 위의 데이터 셋에 행과 열을 각각 추가해주세요 (행 먼저 추가하고 열 추가)\n",
        "# 행과 열의 이름은 순서대로 따라가시면됩니다\n",
        "# 열에 추가할 데이터를 정하기 귀찮으면 range를 와 len을 활용해보세요!\n",
        "# 이때 들어가는 데이터는 자유롭게 작성해주시면 됩니다.\n",
        "\n",
        "#######\n",
        "\n",
        "#행 열 추가하는 코드\n",
        "\n",
        "\n",
        "#######\n",
        "# 행 추가\n",
        "df_1 = pd.DataFrame(df)\n",
        "df_1.loc['5']=range(len(y_data))\n",
        "df_1\n",
        "# 열 추가\n",
        "df_1['e']=range(len(df_1))\n",
        "df_1\n",
        "\n",
        "\n",
        "#######\n",
        "\n",
        "\n",
        "#행 열 제거하는 코드\n",
        "# 데이터를 확인해서 a,b,c,d컬럼의 값이 1인 행을 제거해주세요\n",
        "# 그리고 a열을 제거해주세요\n",
        "\n",
        "\n",
        "#######\n",
        "df_1 = df_1.drop(index=3)\n",
        "df_1 \n",
        "df_1 = df_1.drop('a',axis=1)\n",
        "df_1\n",
        "df_1.to_csv('/content/drive/MyDrive/Colab Notebooks/dataset.csv',index=False)\n",
        "\n",
        "# pd.read~~\n",
        "\n",
        "new_df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset.csv')\n",
        "new_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 4)    a  b  c  d\n",
            "0  2 -1  4 -1\n",
            "1  3 -2  5 -1\n",
            "2  4 -3  6 -1\n",
            "(4,) a    12\n",
            "b    51\n",
            "c    13\n",
            "d    21\n",
            "Name: 4, dtype: int64\n",
            "(4, 4)    a  b  c  d\n",
            "0  2 -1  4 -1\n",
            "1  3 -2  5 -1\n",
            "2  4 -3  6 -1\n",
            "3  1  1  1  1\n",
            "(4,) a    12\n",
            "b    51\n",
            "c    13\n",
            "d    21\n",
            "Name: 4, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-3</td>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51</td>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    b   c   d  e\n",
              "0  -1   4  -1  0\n",
              "1  -2   5  -1  1\n",
              "2  -3   6  -1  2\n",
              "3  51  13  21  4\n",
              "4   1   2   3  5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl-r8t7OWN_j"
      },
      "source": [
        "# 문제 3\n",
        "(b) Instance 수가 아니라 독립변수의 수만큼 가중치 수가 필요하다.\n",
        "\n",
        "(c) \n",
        "a : data sample의 개수\n",
        "   \n",
        "b : 변수의 개수 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0dqziVjviX8"
      },
      "source": [
        "# 문제 4\n",
        "\n",
        "\n",
        "# Base code\n",
        "x_data = [[49, 56, 59],[70, 54, 48],[52, 47, 42],\n",
        "          [41, 44, 62],[65, 64, 68]] # x_data수정\n",
        "y_data = [[173],[168],[153],[135],[180]] # y_data수정\n",
        "\n",
        "\n",
        "# placeholders for a tensor that will be always fed.\n",
        "X = tf.placeholder(tf.float32, shape=[None, 3]) # shape 수정\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1]) # shape 수정\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "# Hypothesis\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "# Simplified cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5) # learning_rate 수정\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "    cost_val, hy_val, _ = sess.run(\n",
        "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
        "    if step % 10 == 0:\n",
        "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbXU4ehNYXi5",
        "outputId": "f7abf265-d9c9-4cf1-e25f-d3d921908afe"
      },
      "source": [
        "# 문제 5\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "Data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Q3.csv',header=None) #데이터를 파일에서 가져옴 \n",
        "Data\n",
        "x = Data.iloc[:, 0:-1] # x_data는 처음부터 마지막 컬럼 전까지 측정값\n",
        "y = Data.iloc[:, [-1]] # y_data는 마지막 컬럼, 결과값\n",
        "\n",
        "X = tf.placeholder(tf.float32,shape=[None,7]) #n개의 데이터가 *개의 측정값으로 구성 \n",
        "Y = tf.placeholder(tf.float32,shape=[None,1]) #n개의 하나의 결과치로 구성\n",
        "\n",
        "#가중치 계산하기\n",
        "W = tf.Variable(tf.random_uniform(\n",
        "    shape=[7,1], minval=-1.0, maxval=1.0, dtype=tf.float32)) \n",
        "\n",
        "#sigmoid를 이용하여 가설 구하기\n",
        "hypothesis = tf.sigmoid(tf.matmul(X, W)) \n",
        "# sigmoid 함수를 사용하지 않고도 한 번 구해보세요~ \n",
        "# hypothesis = tf.div(1.,1.+tf.exp(tf.matmul(X,W)))\n",
        "\n",
        "#cost 계산 \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
        "\n",
        "#cost를 줄이기 위해 학습\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "#Accuracy계산\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32) # 결과값이 0.5이상이면 1 아니면 0\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
        "#계산한 결과가 결과값과 같은지 확률을 계산해요\n",
        "\n",
        "# 세션을 할당하고 초기화 해줍니다.\n",
        "with tf.Session() as sess: \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(10001):#루프값을 바꿔가며 정확도의 차이를 확인해보세요\n",
        "        sess.run(train, feed_dict={X:x,Y:y})\n",
        "        if step % 200 == 0:#200번 돌때마다 step과 cost를 출력해보세요\n",
        "            print(step, sess.run(cost, feed_dict={\n",
        "                  X:x,Y:y }), sess.run(W))\n",
        "\n",
        "   #실제로 학습된 결과로 다시 파일의 내용을 측정해보고 얼마나 정확한지 Accuracy를\n",
        "   #출력해봐요\n",
        "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
        "                       feed_dict={X: x, Y: y})\n",
        "    print (\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)\n",
        "\n",
        "\t#Accuracy값을 통해 몇퍼센트 확률로 코로나에 걸렸는지 아닌지를 판별 가능합니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6835273 [[-0.2193787 ]\n",
            " [-0.6822635 ]\n",
            " [-0.37521502]\n",
            " [ 0.36949903]\n",
            " [ 0.11859208]\n",
            " [-0.72961956]\n",
            " [ 0.5613048 ]]\n",
            "200 0.5657974 [[-0.2464155 ]\n",
            " [-0.62580377]\n",
            " [-0.5300924 ]\n",
            " [ 0.1673167 ]\n",
            " [ 0.06020528]\n",
            " [-1.0123564 ]\n",
            " [ 0.2815483 ]]\n",
            "400 0.5208001 [[-0.29819945]\n",
            " [-0.59536517]\n",
            " [-0.6265368 ]\n",
            " [ 0.03766978]\n",
            " [ 0.01080253]\n",
            " [-1.1769507 ]\n",
            " [ 0.1103539 ]]\n",
            "600 0.49993902 [[-0.36253223]\n",
            " [-0.57913554]\n",
            " [-0.6912755 ]\n",
            " [-0.05204571]\n",
            " [-0.03365736]\n",
            " [-1.2778406 ]\n",
            " [-0.0013467 ]]\n",
            "800 0.48816565 [[-0.43307972]\n",
            " [-0.57092166]\n",
            " [-0.73762053]\n",
            " [-0.11832163]\n",
            " [-0.07506222]\n",
            " [-1.3422611 ]\n",
            " [-0.07841098]]\n",
            "1000 0.48028857 [[-0.506383  ]\n",
            " [-0.5673419 ]\n",
            " [-0.7725562 ]\n",
            " [-0.16985217]\n",
            " [-0.11435324]\n",
            " [-1.3846105 ]\n",
            " [-0.13402155]]\n",
            "1200 0.47430193 [[-0.58043647]\n",
            " [-0.56643593]\n",
            " [-0.8000325 ]\n",
            " [-0.21156585]\n",
            " [-0.15204404]\n",
            " [-1.41308   ]\n",
            " [-0.17568728]]\n",
            "1400 0.46935564 [[-0.6540288 ]\n",
            " [-0.5670097 ]\n",
            " [-0.82242906]\n",
            " [-0.2464382 ]\n",
            " [-0.18843777]\n",
            " [-1.4326102 ]\n",
            " [-0.2079507 ]]\n",
            "1600 0.46506009 [[-0.7264121 ]\n",
            " [-0.5683145 ]\n",
            " [-0.8412476 ]\n",
            " [-0.27635634]\n",
            " [-0.22372594]\n",
            " [-1.4463091 ]\n",
            " [-0.23368795]]\n",
            "1800 0.46122235 [[-0.797126  ]\n",
            " [-0.5698707 ]\n",
            " [-0.8574721 ]\n",
            " [-0.3025643 ]\n",
            " [-0.25803667]\n",
            " [-1.4561917 ]\n",
            " [-0.2547833 ]]\n",
            "2000 0.45773846 [[-0.86589396]\n",
            " [-0.5713736 ]\n",
            " [-0.87176424]\n",
            " [-0.32590687]\n",
            " [-0.29146078]\n",
            " [-1.4635903 ]\n",
            " [-0.2725031 ]]\n",
            "2200 0.4545469 [[-0.93256205]\n",
            " [-0.5726268 ]\n",
            " [-0.88457894]\n",
            " [-0.3469739 ]\n",
            " [-0.32406533]\n",
            " [-1.4693934 ]\n",
            " [-0.28771472]]\n",
            "2400 0.451607 [[-0.9970576 ]\n",
            " [-0.57350993]\n",
            " [-0.8962339 ]\n",
            " [-0.36618537]\n",
            " [-0.35590315]\n",
            " [-1.4741994 ]\n",
            " [-0.30102256]]\n",
            "2600 0.44888952 [[-1.0593626 ]\n",
            " [-0.5739522 ]\n",
            " [-0.90695524]\n",
            " [-0.3838476 ]\n",
            " [-0.38701683]\n",
            " [-1.4784098 ]\n",
            " [-0.31285343]]\n",
            "2800 0.4463711 [[-1.1194966 ]\n",
            " [-0.5739166 ]\n",
            " [-0.91690624]\n",
            " [-0.4001884 ]\n",
            " [-0.4174425 ]\n",
            " [-1.482292  ]\n",
            " [-0.3235111 ]]\n",
            "3000 0.4440327 [[-1.1775026 ]\n",
            " [-0.573389  ]\n",
            " [-0.9262065 ]\n",
            " [-0.41538158]\n",
            " [-0.44721133]\n",
            " [-1.4860215 ]\n",
            " [-0.33321673]]\n",
            "3200 0.44185784 [[-1.2334399 ]\n",
            " [-0.57237023]\n",
            " [-0.93494505]\n",
            " [-0.42956138]\n",
            " [-0.47635132]\n",
            " [-1.489717  ]\n",
            " [-0.342132  ]]\n",
            "3400 0.43983185 [[-1.2873771 ]\n",
            " [-0.5708707 ]\n",
            " [-0.9431894 ]\n",
            " [-0.44283476]\n",
            " [-0.50488794]\n",
            " [-1.4934393 ]\n",
            " [-0.35037762]]\n",
            "3600 0.43794194 [[-1.339389  ]\n",
            " [-0.56890786]\n",
            " [-0.9509918 ]\n",
            " [-0.45528847]\n",
            " [-0.53284425]\n",
            " [-1.4972366 ]\n",
            " [-0.3580447 ]]\n",
            "3800 0.43617633 [[-1.3895518 ]\n",
            " [-0.56650215]\n",
            " [-0.95839363]\n",
            " [-0.46699446]\n",
            " [-0.560242  ]\n",
            " [-1.5011269 ]\n",
            " [-0.36520383]]\n",
            "4000 0.4345249 [[-1.437942  ]\n",
            " [-0.5636765 ]\n",
            " [-0.9654281 ]\n",
            " [-0.47801337]\n",
            " [-0.58710164]\n",
            " [-1.5051187 ]\n",
            " [-0.37191027]]\n",
            "4200 0.43297806 [[-1.4846361 ]\n",
            " [-0.5604548 ]\n",
            " [-0.97212255]\n",
            " [-0.4883976 ]\n",
            " [-0.613442  ]\n",
            " [-1.5092114 ]\n",
            " [-0.37820843]]\n",
            "4400 0.4315274 [[-1.5297085 ]\n",
            " [-0.55686104]\n",
            " [-0.97850007]\n",
            " [-0.49819282]\n",
            " [-0.6392813 ]\n",
            " [-1.5133976 ]\n",
            " [-0.38413492]]\n",
            "4600 0.4301651 [[-1.57323   ]\n",
            " [-0.55291873]\n",
            " [-0.9845804 ]\n",
            " [-0.50743955]\n",
            " [-0.6646363 ]\n",
            " [-1.5176681 ]\n",
            " [-0.38972035]]\n",
            "4800 0.42888436 [[-1.61527   ]\n",
            " [-0.54865056]\n",
            " [-0.9903808 ]\n",
            " [-0.5161741 ]\n",
            " [-0.6895235 ]\n",
            " [-1.5220094 ]\n",
            " [-0.39499092]]\n",
            "5000 0.4276788 [[-1.6558933 ]\n",
            " [-0.5440786 ]\n",
            " [-0.99591666]\n",
            " [-0.5244292 ]\n",
            " [-0.7139582 ]\n",
            " [-1.5264101 ]\n",
            " [-0.39996967]]\n",
            "5200 0.42654255 [[-1.6951638 ]\n",
            " [-0.53922343]\n",
            " [-1.001202  ]\n",
            " [-0.53223515]\n",
            " [-0.7379548 ]\n",
            " [-1.5308568 ]\n",
            " [-0.4046767 ]]\n",
            "5400 0.4254706 [[-1.73314   ]\n",
            " [-0.534105  ]\n",
            " [-1.006249  ]\n",
            " [-0.53961945]\n",
            " [-0.76152754]\n",
            " [-1.5353351 ]\n",
            " [-0.40913036]]\n",
            "5600 0.42445797 [[-1.769879  ]\n",
            " [-0.5287417 ]\n",
            " [-1.0110697 ]\n",
            " [-0.5466073 ]\n",
            " [-0.7846898 ]\n",
            " [-1.5398382 ]\n",
            " [-0.41334707]]\n",
            "5800 0.4235005 [[-1.8054342 ]\n",
            " [-0.5231511 ]\n",
            " [-1.0156742 ]\n",
            " [-0.5532223 ]\n",
            " [-0.80745405]\n",
            " [-1.5443443 ]\n",
            " [-0.41734198]]\n",
            "6000 0.42259422 [[-1.8398566 ]\n",
            " [-0.51734954]\n",
            " [-1.0200735 ]\n",
            " [-0.5594867 ]\n",
            " [-0.82983243]\n",
            " [-1.5488504 ]\n",
            " [-0.42112938]]\n",
            "6200 0.42173547 [[-1.8731945 ]\n",
            " [-0.51135236]\n",
            " [-1.0242759 ]\n",
            " [-0.5654204 ]\n",
            " [-0.8518365 ]\n",
            " [-1.5533478 ]\n",
            " [-0.42472184]]\n",
            "6400 0.42092088 [[-1.9054933 ]\n",
            " [-0.5051741 ]\n",
            " [-1.0282909 ]\n",
            " [-0.57104254]\n",
            " [-0.87347746]\n",
            " [-1.5578239 ]\n",
            " [-0.4281317 ]]\n",
            "6600 0.42014757 [[-1.9367961 ]\n",
            " [-0.49882796]\n",
            " [-1.0321258 ]\n",
            " [-0.57637113]\n",
            " [-0.8947656 ]\n",
            " [-1.5622716 ]\n",
            " [-0.43137014]]\n",
            "6800 0.4194126 [[-1.9671441 ]\n",
            " [-0.49232686]\n",
            " [-1.0357894 ]\n",
            " [-0.5814227 ]\n",
            " [-0.9157111 ]\n",
            " [-1.5666844 ]\n",
            " [-0.43444782]]\n",
            "7000 0.41871354 [[-1.9965757 ]\n",
            " [-0.48568234]\n",
            " [-1.0392886 ]\n",
            " [-0.58621275]\n",
            " [-0.9363239 ]\n",
            " [-1.571055  ]\n",
            " [-0.4373746 ]]\n",
            "7200 0.41804802 [[-2.0251281 ]\n",
            " [-0.47890556]\n",
            " [-1.04263   ]\n",
            " [-0.5907562 ]\n",
            " [-0.95661306]\n",
            " [-1.575377  ]\n",
            " [-0.44016   ]]\n",
            "7400 0.4174139 [[-2.0528362 ]\n",
            " [-0.47200683]\n",
            " [-1.0458211 ]\n",
            " [-0.5950664 ]\n",
            " [-0.9765876 ]\n",
            " [-1.579646  ]\n",
            " [-0.44281265]]\n",
            "7600 0.41680908 [[-2.0797322 ]\n",
            " [-0.4649959 ]\n",
            " [-1.0488675 ]\n",
            " [-0.5991566 ]\n",
            " [-0.99625605]\n",
            " [-1.583858  ]\n",
            " [-0.44534078]]\n",
            "7800 0.41623187 [[-2.1058488 ]\n",
            " [-0.4578818 ]\n",
            " [-1.0517752 ]\n",
            " [-0.60303885]\n",
            " [-1.0156267 ]\n",
            " [-1.5880073 ]\n",
            " [-0.44775224]]\n",
            "8000 0.41568044 [[-2.1312156 ]\n",
            " [-0.45067298]\n",
            " [-1.0545504 ]\n",
            " [-0.6067246 ]\n",
            " [-1.0347072 ]\n",
            " [-1.5920914 ]\n",
            " [-0.45005435]]\n",
            "8200 0.41515335 [[-2.155861  ]\n",
            " [-0.4433775 ]\n",
            " [-1.0571982 ]\n",
            " [-0.6102246 ]\n",
            " [-1.0535053 ]\n",
            " [-1.5961072 ]\n",
            " [-0.45225385]]\n",
            "8400 0.4146491 [[-2.1798115 ]\n",
            " [-0.43600267]\n",
            " [-1.0597231 ]\n",
            " [-0.61354905]\n",
            " [-1.0720278 ]\n",
            " [-1.6000521 ]\n",
            " [-0.4543573 ]]\n",
            "8600 0.41416636 [[-2.2030935 ]\n",
            " [-0.4285555 ]\n",
            " [-1.0621307 ]\n",
            " [-0.61670744]\n",
            " [-1.0902821 ]\n",
            " [-1.6039239 ]\n",
            " [-0.45637077]]\n",
            "8800 0.4137038 [[-2.2257302 ]\n",
            " [-0.42104265]\n",
            " [-1.0644249 ]\n",
            " [-0.6197088 ]\n",
            " [-1.1082749 ]\n",
            " [-1.6077209 ]\n",
            " [-0.45829996]]\n",
            "9000 0.41326043 [[-2.2477465 ]\n",
            " [-0.41347024]\n",
            " [-1.0666115 ]\n",
            " [-0.62256134]\n",
            " [-1.1260128 ]\n",
            " [-1.6114407 ]\n",
            " [-0.46015036]]\n",
            "9200 0.41283503 [[-2.2691638 ]\n",
            " [-0.40584412]\n",
            " [-1.0686928 ]\n",
            " [-0.62527317]\n",
            " [-1.1435015 ]\n",
            " [-1.6150819 ]\n",
            " [-0.46192703]]\n",
            "9400 0.41242662 [[-2.290004  ]\n",
            " [-0.3981696 ]\n",
            " [-1.0706744 ]\n",
            " [-0.62785184]\n",
            " [-1.1607474 ]\n",
            " [-1.6186448 ]\n",
            " [-0.46363464]]\n",
            "9600 0.4120343 [[-2.3102868 ]\n",
            " [-0.39045188]\n",
            " [-1.0725595 ]\n",
            " [-0.6303047 ]\n",
            " [-1.1777562 ]\n",
            " [-1.6221281 ]\n",
            " [-0.46527788]]\n",
            "9800 0.4116572 [[-2.3300312]\n",
            " [-0.3826958]\n",
            " [-1.074352 ]\n",
            " [-0.6326381]\n",
            " [-1.194533 ]\n",
            " [-1.6255302]\n",
            " [-0.4668607]]\n",
            "10000 0.4112945 [[-2.3492556 ]\n",
            " [-0.37490597]\n",
            " [-1.0760553 ]\n",
            " [-0.63485867]\n",
            " [-1.2110844 ]\n",
            " [-1.6288526 ]\n",
            " [-0.46838722]]\n",
            "\n",
            "Hypothesis:  [[0.6021363 ]\n",
            " [0.7063599 ]\n",
            " [0.4539896 ]\n",
            " [0.89932406]\n",
            " [0.288952  ]\n",
            " [0.5741667 ]\n",
            " [0.07599708]\n",
            " [0.59100616]\n",
            " [0.9359591 ]\n",
            " [0.8372381 ]\n",
            " [0.83268654]\n",
            " [0.9595828 ]\n",
            " [0.9567491 ]\n",
            " [0.96708876]\n",
            " [0.3799304 ]\n",
            " [0.47481176]\n",
            " [0.9652825 ]\n",
            " [0.42269135]\n",
            " [0.5736945 ]\n",
            " [0.10826764]\n",
            " [0.8929012 ]\n",
            " [0.84296465]\n",
            " [0.9409169 ]\n",
            " [0.78568137]\n",
            " [0.9118867 ]\n",
            " [0.44275206]\n",
            " [0.97414505]\n",
            " [0.8513853 ]\n",
            " [0.8210608 ]\n",
            " [0.86032516]\n",
            " [0.925333  ]\n",
            " [0.95417583]\n",
            " [0.89704454]\n",
            " [0.8635286 ]\n",
            " [0.9099027 ]\n",
            " [0.9515276 ]\n",
            " [0.9340303 ]\n",
            " [0.9154687 ]\n",
            " [0.9302745 ]\n",
            " [0.8516676 ]\n",
            " [0.7603199 ]\n",
            " [0.9244476 ]\n",
            " [0.8106704 ]\n",
            " [0.9325665 ]\n",
            " [0.9166266 ]\n",
            " [0.86893517]\n",
            " [0.894898  ]\n",
            " [0.6640312 ]\n",
            " [0.74825376]\n",
            " [0.7694588 ]\n",
            " [0.93624157]\n",
            " [0.98484087]\n",
            " [0.95426905]\n",
            " [0.7311109 ]\n",
            " [0.7220416 ]\n",
            " [0.9745412 ]\n",
            " [0.71459675]\n",
            " [0.74185944]\n",
            " [0.8737298 ]\n",
            " [0.8267541 ]\n",
            " [0.95550466]\n",
            " [0.93982923]\n",
            " [0.71632004]\n",
            " [0.5324843 ]\n",
            " [0.95539445]\n",
            " [0.89396214]\n",
            " [0.8600479 ]\n",
            " [0.9174566 ]\n",
            " [0.95385313]\n",
            " [0.30023456]\n",
            " [0.84710455]\n",
            " [0.90571827]\n",
            " [0.6357894 ]\n",
            " [0.79993814]\n",
            " [0.85505384]\n",
            " [0.8046776 ]\n",
            " [0.8992914 ]\n",
            " [0.85885155]\n",
            " [0.95570207]\n",
            " [0.9159291 ]\n",
            " [0.88181674]\n",
            " [0.9434372 ]\n",
            " [0.59254825]\n",
            " [0.8956321 ]\n",
            " [0.7259455 ]\n",
            " [0.81291705]\n",
            " [0.93652177]\n",
            " [0.7874477 ]\n",
            " [0.76670074]\n",
            " [0.7978163 ]\n",
            " [0.9500469 ]\n",
            " [0.6824461 ]\n",
            " [0.496033  ]\n",
            " [0.95980513]\n",
            " [0.6986856 ]\n",
            " [0.80354875]\n",
            " [0.39624348]\n",
            " [0.41148335]\n",
            " [0.26108485]\n",
            " [0.4068585 ]\n",
            " [0.9231006 ]\n",
            " [0.89802337]\n",
            " [0.9691055 ]\n",
            " [0.37278187]\n",
            " [0.635846  ]\n",
            " [0.87657285]\n",
            " [0.8292408 ]\n",
            " [0.8710493 ]\n",
            " [0.5402133 ]\n",
            " [0.8721701 ]\n",
            " [0.77358764]\n",
            " [0.6529662 ]\n",
            " [0.7696959 ]\n",
            " [0.92139304]\n",
            " [0.83649015]\n",
            " [0.8031456 ]\n",
            " [0.8915919 ]\n",
            " [0.8897572 ]\n",
            " [0.9647484 ]\n",
            " [0.41586795]\n",
            " [0.8414704 ]\n",
            " [0.49775714]\n",
            " [0.49766186]\n",
            " [0.39570516]\n",
            " [0.92194873]\n",
            " [0.8605671 ]\n",
            " [0.936692  ]\n",
            " [0.93180573]\n",
            " [0.67364883]\n",
            " [0.26221466]\n",
            " [0.8398932 ]\n",
            " [0.80349493]\n",
            " [0.9543272 ]\n",
            " [0.8454981 ]\n",
            " [0.81390417]\n",
            " [0.712262  ]\n",
            " [0.62096757]\n",
            " [0.8267075 ]\n",
            " [0.97106713]\n",
            " [0.8394697 ]\n",
            " [0.8831413 ]\n",
            " [0.25906783]\n",
            " [0.4065971 ]\n",
            " [0.91725236]\n",
            " [0.3897214 ]\n",
            " [0.9522034 ]\n",
            " [0.48414028]\n",
            " [0.41614982]\n",
            " [0.851989  ]\n",
            " [0.7950975 ]\n",
            " [0.74099576]\n",
            " [0.22230569]\n",
            " [0.2486814 ]\n",
            " [0.8185009 ]\n",
            " [0.624373  ]\n",
            " [0.9436779 ]\n",
            " [0.9636779 ]\n",
            " [0.83849037]\n",
            " [0.48746684]\n",
            " [0.01955858]\n",
            " [0.8851444 ]\n",
            " [0.43994367]\n",
            " [0.61008185]\n",
            " [0.9590087 ]\n",
            " [0.7122176 ]\n",
            " [0.97067845]\n",
            " [0.8390192 ]\n",
            " [0.91403186]\n",
            " [0.93179345]\n",
            " [0.7297988 ]\n",
            " [0.7158888 ]\n",
            " [0.23448214]\n",
            " [0.7398465 ]\n",
            " [0.29984444]\n",
            " [0.7858615 ]\n",
            " [0.91197485]\n",
            " [0.79182553]\n",
            " [0.7463978 ]\n",
            " [0.97273195]\n",
            " [0.9158424 ]\n",
            " [0.8924316 ]\n",
            " [0.72277415]\n",
            " [0.80257046]\n",
            " [0.9170422 ]\n",
            " [0.5459309 ]\n",
            " [0.66124684]\n",
            " [0.55028504]\n",
            " [0.85708785]\n",
            " [0.71971786]\n",
            " [0.76273763]\n",
            " [0.8449373 ]\n",
            " [0.4593925 ]\n",
            " [0.46662062]\n",
            " [0.5747639 ]\n",
            " [0.70746577]\n",
            " [0.5019589 ]\n",
            " [0.9298976 ]\n",
            " [0.7859849 ]\n",
            " [0.9078663 ]\n",
            " [0.7577442 ]\n",
            " [0.7987575 ]\n",
            " [0.9113797 ]\n",
            " [0.93478996]\n",
            " [0.62216955]\n",
            " [0.8939677 ]\n",
            " [0.57971925]\n",
            " [0.8293216 ]\n",
            " [0.86156046]\n",
            " [0.5195639 ]\n",
            " [0.7825259 ]\n",
            " [0.36367542]\n",
            " [0.9705786 ]\n",
            " [0.8760777 ]\n",
            " [0.91489154]\n",
            " [0.46285105]\n",
            " [0.7117406 ]\n",
            " [0.55021816]\n",
            " [0.66781414]\n",
            " [0.7317955 ]\n",
            " [0.82189465]\n",
            " [0.6120793 ]\n",
            " [0.7998525 ]\n",
            " [0.94520044]\n",
            " [0.6257131 ]\n",
            " [0.6977272 ]\n",
            " [0.8497397 ]\n",
            " [0.8919028 ]\n",
            " [0.9293663 ]\n",
            " [0.8338387 ]\n",
            " [0.92646   ]\n",
            " [0.9185712 ]\n",
            " [0.96939003]\n",
            " [0.421472  ]\n",
            " [0.87866545]\n",
            " [0.87522167]\n",
            " [0.65052015]\n",
            " [0.8104781 ]\n",
            " [0.86434215]\n",
            " [0.78213894]\n",
            " [0.42297417]\n",
            " [0.89110076]\n",
            " [0.9317286 ]\n",
            " [0.5739911 ]\n",
            " [0.97185093]\n",
            " [0.3205188 ]\n",
            " [0.8513218 ]\n",
            " [0.9713011 ]\n",
            " [0.5010397 ]\n",
            " [0.5319629 ]\n",
            " [0.7303119 ]\n",
            " [0.5309315 ]\n",
            " [0.31196398]\n",
            " [0.90929115]\n",
            " [0.92292345]\n",
            " [0.8783787 ]\n",
            " [0.7085995 ]\n",
            " [0.7089655 ]\n",
            " [0.7463137 ]\n",
            " [0.85672784]\n",
            " [0.86848223]\n",
            " [0.96630776]\n",
            " [0.81296116]\n",
            " [0.81745934]\n",
            " [0.684119  ]\n",
            " [0.9366741 ]\n",
            " [0.9602665 ]\n",
            " [0.6790279 ]\n",
            " [0.6349081 ]\n",
            " [0.8954045 ]\n",
            " [0.25754464]\n",
            " [0.4902241 ]\n",
            " [0.6880022 ]\n",
            " [0.7324831 ]\n",
            " [0.9158587 ]\n",
            " [0.92361414]\n",
            " [0.97153115]\n",
            " [0.48791736]\n",
            " [0.91522574]\n",
            " [0.9145464 ]\n",
            " [0.71683913]\n",
            " [0.9623393 ]\n",
            " [0.92024326]\n",
            " [0.7068665 ]\n",
            " [0.85901916]\n",
            " [0.9413599 ]\n",
            " [0.85320646]\n",
            " [0.8941415 ]\n",
            " [0.9266611 ]\n",
            " [0.9614221 ]\n",
            " [0.74845505]\n",
            " [0.7447002 ]\n",
            " [0.86776257]\n",
            " [0.88695556]\n",
            " [0.8282634 ]\n",
            " [0.93005407]\n",
            " [0.37061048]\n",
            " [0.5681909 ]\n",
            " [0.8633796 ]\n",
            " [0.7895918 ]\n",
            " [0.91754735]\n",
            " [0.9369459 ]\n",
            " [0.8003384 ]\n",
            " [0.736273  ]\n",
            " [0.8864408 ]\n",
            " [0.13731766]\n",
            " [0.23549312]\n",
            " [0.7450341 ]\n",
            " [0.8593654 ]\n",
            " [0.4878016 ]\n",
            " [0.84300137]\n",
            " [0.67987955]\n",
            " [0.5396771 ]\n",
            " [0.82226396]\n",
            " [0.5516457 ]\n",
            " [0.8951759 ]\n",
            " [0.90403366]\n",
            " [0.718378  ]\n",
            " [0.9256654 ]\n",
            " [0.78740275]\n",
            " [0.81220734]\n",
            " [0.5734524 ]\n",
            " [0.47642928]\n",
            " [0.8718091 ]\n",
            " [0.71716976]\n",
            " [0.9202539 ]\n",
            " [0.9365012 ]\n",
            " [0.96602184]\n",
            " [0.75340474]\n",
            " [0.85799146]\n",
            " [0.6216072 ]\n",
            " [0.6615147 ]\n",
            " [0.60275674]\n",
            " [0.94483423]\n",
            " [0.640611  ]\n",
            " [0.3581252 ]\n",
            " [0.9544474 ]\n",
            " [0.9140291 ]\n",
            " [0.6327605 ]\n",
            " [0.9396056 ]\n",
            " [0.8953163 ]\n",
            " [0.9243163 ]\n",
            " [0.97642106]\n",
            " [0.90394676]\n",
            " [0.5733008 ]\n",
            " [0.907931  ]\n",
            " [0.5155231 ]\n",
            " [0.9545619 ]\n",
            " [0.7138757 ]\n",
            " [0.8607863 ]\n",
            " [0.9333874 ]\n",
            " [0.89984214]\n",
            " [0.91703886]\n",
            " [0.582378  ]\n",
            " [0.90514684]\n",
            " [0.9840213 ]\n",
            " [0.8818642 ]\n",
            " [0.7908234 ]\n",
            " [0.5207454 ]\n",
            " [0.4997831 ]\n",
            " [0.78169507]\n",
            " [0.8373064 ]\n",
            " [0.63473654]\n",
            " [0.8570125 ]\n",
            " [0.7269294 ]\n",
            " [0.78343713]\n",
            " [0.9237963 ]\n",
            " [0.88515913]\n",
            " [0.656713  ]\n",
            " [0.7855294 ]\n",
            " [0.9676509 ]\n",
            " [0.9409702 ]\n",
            " [0.70616174]\n",
            " [0.4735598 ]\n",
            " [0.15790853]\n",
            " [0.93246424]\n",
            " [0.20457527]\n",
            " [0.9265468 ]\n",
            " [0.87729704]\n",
            " [0.8872084 ]\n",
            " [0.7082131 ]\n",
            " [0.9174731 ]\n",
            " [0.42096114]\n",
            " [0.83762413]\n",
            " [0.95878696]\n",
            " [0.55452883]\n",
            " [0.56709766]\n",
            " [0.90054464]\n",
            " [0.9065378 ]\n",
            " [0.69577295]\n",
            " [0.8845514 ]\n",
            " [0.8387665 ]\n",
            " [0.8842088 ]\n",
            " [0.59282225]\n",
            " [0.7676831 ]\n",
            " [0.88442457]\n",
            " [0.6649883 ]\n",
            " [0.9039397 ]\n",
            " [0.87546337]\n",
            " [0.8635443 ]\n",
            " [0.8676122 ]\n",
            " [0.96938884]\n",
            " [0.8024214 ]\n",
            " [0.55846334]\n",
            " [0.9030138 ]\n",
            " [0.8154115 ]\n",
            " [0.97804266]\n",
            " [0.8604766 ]\n",
            " [0.82089454]\n",
            " [0.5312588 ]\n",
            " [0.80777514]\n",
            " [0.9262144 ]\n",
            " [0.9565178 ]\n",
            " [0.9538913 ]\n",
            " [0.8715329 ]\n",
            " [0.7610643 ]\n",
            " [0.87692076]\n",
            " [0.6251012 ]\n",
            " [0.7852459 ]\n",
            " [0.8440633 ]\n",
            " [0.87701607]\n",
            " [0.733128  ]\n",
            " [0.798329  ]\n",
            " [0.87017655]\n",
            " [0.6861604 ]\n",
            " [0.52764523]\n",
            " [0.9535559 ]\n",
            " [0.940618  ]\n",
            " [0.89174014]\n",
            " [0.5816039 ]\n",
            " [0.30580807]\n",
            " [0.84528357]\n",
            " [0.931079  ]\n",
            " [0.7024198 ]\n",
            " [0.9572134 ]\n",
            " [0.9373926 ]\n",
            " [0.8869196 ]\n",
            " [0.8591161 ]\n",
            " [0.7623951 ]\n",
            " [0.7903139 ]\n",
            " [0.876192  ]\n",
            " [0.6940063 ]\n",
            " [0.34662294]\n",
            " [0.9284595 ]\n",
            " [0.94361484]\n",
            " [0.80242205]\n",
            " [0.94492257]\n",
            " [0.87630653]\n",
            " [0.939927  ]\n",
            " [0.7510092 ]\n",
            " [0.8848674 ]\n",
            " [0.69521254]\n",
            " [0.92100585]\n",
            " [0.95589244]\n",
            " [0.6085096 ]\n",
            " [0.87237734]\n",
            " [0.8989707 ]\n",
            " [0.73753875]\n",
            " [0.40000606]\n",
            " [0.9172164 ]\n",
            " [0.8255228 ]\n",
            " [0.7897929 ]\n",
            " [0.6362748 ]\n",
            " [0.95391536]\n",
            " [0.647374  ]\n",
            " [0.8759925 ]\n",
            " [0.27999973]\n",
            " [0.93949795]\n",
            " [0.46498188]\n",
            " [0.84794307]\n",
            " [0.5921013 ]\n",
            " [0.8162062 ]\n",
            " [0.6783934 ]\n",
            " [0.55174756]\n",
            " [0.85773027]\n",
            " [0.9479958 ]\n",
            " [0.47136015]\n",
            " [0.9523631 ]\n",
            " [0.89394855]\n",
            " [0.90639234]\n",
            " [0.854308  ]\n",
            " [0.5653625 ]\n",
            " [0.47279474]\n",
            " [0.6790195 ]\n",
            " [0.18798262]\n",
            " [0.9629186 ]\n",
            " [0.6308286 ]\n",
            " [0.96101385]\n",
            " [0.9402071 ]\n",
            " [0.5917244 ]\n",
            " [0.30563283]\n",
            " [0.7622452 ]\n",
            " [0.86793345]\n",
            " [0.8011687 ]\n",
            " [0.98840976]\n",
            " [0.84398305]\n",
            " [0.689596  ]\n",
            " [0.06678069]\n",
            " [0.87229705]\n",
            " [0.8018209 ]\n",
            " [0.89031917]\n",
            " [0.7549484 ]\n",
            " [0.5891313 ]\n",
            " [0.69064707]\n",
            " [0.9278439 ]\n",
            " [0.9118422 ]\n",
            " [0.8451876 ]\n",
            " [0.92506826]\n",
            " [0.9058851 ]\n",
            " [0.8258773 ]\n",
            " [0.93088627]\n",
            " [0.97553337]\n",
            " [0.9063475 ]\n",
            " [0.7275324 ]\n",
            " [0.83558613]\n",
            " [0.87993395]\n",
            " [0.6271108 ]\n",
            " [0.57054174]\n",
            " [0.8111551 ]\n",
            " [0.93145573]\n",
            " [0.9680625 ]\n",
            " [0.8908675 ]\n",
            " [0.8573532 ]\n",
            " [0.78276   ]\n",
            " [0.93462336]\n",
            " [0.6641816 ]\n",
            " [0.9607092 ]\n",
            " [0.46270117]\n",
            " [0.8255966 ]\n",
            " [0.5078749 ]\n",
            " [0.08420169]\n",
            " [0.49512666]\n",
            " [0.87375706]\n",
            " [0.8902829 ]\n",
            " [0.8818553 ]\n",
            " [0.7713546 ]\n",
            " [0.54812783]\n",
            " [0.8960444 ]\n",
            " [0.9496708 ]\n",
            " [0.4760295 ]\n",
            " [0.65769553]\n",
            " [0.3495301 ]\n",
            " [0.8669086 ]\n",
            " [0.9298648 ]\n",
            " [0.9846068 ]\n",
            " [0.8884963 ]\n",
            " [0.39537567]\n",
            " [0.8014644 ]\n",
            " [0.80091345]\n",
            " [0.92904615]\n",
            " [0.76911616]\n",
            " [0.6987396 ]\n",
            " [0.36966342]\n",
            " [0.7410643 ]\n",
            " [0.68815553]\n",
            " [0.92207193]\n",
            " [0.74744123]\n",
            " [0.768173  ]\n",
            " [0.8964739 ]\n",
            " [0.8394667 ]\n",
            " [0.495708  ]\n",
            " [0.8279786 ]\n",
            " [0.7095206 ]\n",
            " [0.28351694]\n",
            " [0.644608  ]\n",
            " [0.9488158 ]\n",
            " [0.90565777]\n",
            " [0.79186547]\n",
            " [0.8917891 ]\n",
            " [0.50621665]\n",
            " [0.8793748 ]\n",
            " [0.78265595]\n",
            " [0.8583709 ]\n",
            " [0.6551044 ]\n",
            " [0.82478225]\n",
            " [0.8668    ]\n",
            " [0.3203997 ]\n",
            " [0.36283422]\n",
            " [0.8760866 ]\n",
            " [0.8532715 ]\n",
            " [0.82890594]\n",
            " [0.9317693 ]\n",
            " [0.80630577]\n",
            " [0.77276146]\n",
            " [0.8406025 ]\n",
            " [0.73402613]\n",
            " [0.7699045 ]\n",
            " [0.8425853 ]\n",
            " [0.7347765 ]\n",
            " [0.54303336]\n",
            " [0.91300786]\n",
            " [0.8815446 ]\n",
            " [0.7986847 ]\n",
            " [0.9252145 ]\n",
            " [0.7467341 ]\n",
            " [0.8935418 ]\n",
            " [0.8033763 ]\n",
            " [0.9185085 ]\n",
            " [0.8924781 ]\n",
            " [0.9453738 ]\n",
            " [0.95290965]\n",
            " [0.3328222 ]\n",
            " [0.8751791 ]\n",
            " [0.7577174 ]\n",
            " [0.8424544 ]\n",
            " [0.92078996]\n",
            " [0.3465361 ]\n",
            " [0.63597214]\n",
            " [0.81235725]\n",
            " [0.21734318]\n",
            " [0.93832326]\n",
            " [0.3970374 ]\n",
            " [0.92139906]\n",
            " [0.8327588 ]\n",
            " [0.8060221 ]\n",
            " [0.9210972 ]\n",
            " [0.6940978 ]\n",
            " [0.91296387]] \n",
            "Correct (Y):  [[1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] \n",
            "Accuracy:  0.81037277\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}